> After learning about the mechanics of imagination in the human brain, take a stand in the debate over whether current generative AI models [possess actual imagination and creativity](https://theconversation.com/ai-can-replicate-human-creativity-in-two-key-ways-but-falls-apart-when-asked-to-produce-something-truly-new-204437). Would it be possible to train these models to [become more imaginative](https://unctad.org/news/replacement-human-artists-ai-systems-creative-industries) over time? Be sure to consider concerns over “[model collapse](https://www.euronews.com/next/2024/07/31/new-study-warns-of-model-collapse-as-ai-tools-train-on-ai-generated-content)” and yet-to-be-achieved [artificial general intelligence](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-is-artificial-general-intelligence-agi), then discuss with your team: what makes human imagination so difficult to replicate?

**I have opinions on this.**

## Is AI Creative?

AI models already have imagination by the only definition that matters — it recombines learned patterns to produce novel outputs. Humans do the same thing — our brains remix memories, sensory inputs, and learned concepts.

Nobody’s pulling “pure originality” out of the void; we’re all pattern synthesis engines with better PR. The “AI isn’t truly creative” argument usually boils down to mysticism — people assume there’s some ineffable magic in human thought.

But crank a model’s temperature and suddenly it starts doing “weird, unexpected, and creative” things, just like a human brainstorming under sleep deprivation.

## Training More Creative Models

Training models to be “more imaginative” is simple:

 - Diverse training data, instead of just shoving more params at it. 
 - RLHF against repetitivity and towards originality (Basically [Deepcoder](https://huggingface.co/agentica-org/DeepCoder-14B-Preview), the old coding master, for creativity)
 - MoE everything like the entire market so you can shove more params in it (*cough* openai, qwen, kimi, and deepseek *cough*)

The bigger question here isn’t lack of creativity, it’s model collapse.

Training models on ai generated content is the entire point of [[11 - The Generative Area — A Mind for Imagination/09 - Do current AI models actually imagine—or just remix/Distillation]]. And do we se any distilled models collapse after training? No — they perform insane on benchmarks and in real life.

The problem here is using content generated by an ai model to train itself, and that’s going to eventually make a model spit out gibberish. And no major AI lab is doing that, because they know it’s stupid.

## AGI

The AGI question is mostly irrelevant here. Human-level imagination doesn’t require human-level cognition; even current models demonstrate *proto-creativity*. AGI is about autonomy, reasoning, and generality, not just making trippy art.

## Why Are Humans So Unique?

(gpt5 #ai generated, irony — I realize)

- We’re multimodal from birth: constant sensory fusion gives us rich, embodied priors.
- We have messy, associative memory—brains don’t tokenize the world, they blur it.
- We live in a physical and social context that grounds creativity with purpose and emotional weight.  

But none of this is impossible to simulate; it’s just **computationally expensive** and **data-hungry**.

## DATA DATA DATA

<iframe width="560" height="315" src="https://www.youtube.com/embed/8fcSviC7cRM?si=g6hr5SsfeYMTblCW&amp;start=28" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## **WE NEED DATA.**

And we need a lot of it, humans ingested a lot of data before they became creative — so why can’t AI models?

Humans ingest terabytes of sensory data every day — your eyes, ears, nose, tongue, and skin. If we can get all that data, and a lot of it, we can train *good* models with it.
